{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b766e8a3-ea3c-4e69-8e6a-0cfd9ab9d556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7ace27-b0b5-4a50-80cd-b52705d62ae6",
   "metadata": {},
   "source": [
    "Suppose one has data that consists of an independent vector and a dependent vector $x_i$ and $y_i$ ($i$ is the ith value in the data set). For example:\n",
    "\n",
    "* $x_i$ is the height of the $i$th person, and $y_i$ is their weight (predict weight using height)\n",
    "* $x_i$ is a picture of a handwritten digit, and $y_i$ is the digit itself (predict numbers from hand written numbers)\n",
    "* $x_i$ is a CT scan of a patient, and $y_i$ are the corresponding pixels corresponding to tumours (my research)\n",
    "\n",
    "The goal of a neural network is as follows. Define a function $f$ that depends on parameters $a$ that makes predictions\n",
    "\n",
    "$$\\hat{y_i} =f(x_i;a)$$\n",
    "\n",
    "One wants to make $\\hat{y_i}$ (the predictions) and $y_i$ (the true values) as close as possible by modifying the values of $a$. What does as close as possible mean? This depends on the task. In general, one defines a similarity function (or **Loss** function) $L(y,\\hat{y})$. The more similar all the $y_i$s and $\\hat{y_i}$s are, the smaller $L$ should be. For example 1 above, this could be as simple as \n",
    "\n",
    "$$L(y,\\hat{y}) = \\sum_i(y_i-\\hat{y_i})^2$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88da39d3-262b-4f6f-8df3-db4e774ccf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[6,2],[5,2],[1,3],[7,6]]).float()\n",
    "y = torch.tensor([1,5,2,5]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc76223e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6., 2.],\n",
       "        [5., 2.],\n",
       "        [1., 3.],\n",
       "        [7., 6.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dec9c2b-620f-4f51-937c-69a614eb5670",
   "metadata": {},
   "source": [
    "* So $x_1 = (6,2)$, $x_2=(5,2)$, ...\n",
    "* So $y_1 = 1$, $y_2=5$, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a5fcca-9fbb-4ff3-a4ac-3e71a52ab625",
   "metadata": {},
   "source": [
    "We want to find a function $f$ that depends on parameters $a$ that lets us get from $x$ to $y$.\n",
    "\n",
    "**Idea**: \n",
    "1. First multiply each element in $x$ by a $8 \\times 2$ matrix (this is 16 parameters $a_i$)\n",
    "2. Then multiply each element in $x$ by a $1 \\times 8$ matrix (this is 8 parameters $a_i$)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ce0629-a928-44a4-bbf0-f939590fa596",
   "metadata": {},
   "source": [
    "Define a matrix (takes in a 2d vector and returns a 8d vector). \n",
    "\n",
    "* **IMPORTANT**: When the matrix is created, it is initially created with random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "198c4106-5b1e-48d5-84f2-9c5ae31ae323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2, out_features=8, bias=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1 = nn.Linear(2,8,bias=False)\n",
    "M1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b93c2b-5355-48d9-98fa-19ae7b24b908",
   "metadata": {},
   "source": [
    "If one passes in a vector $x$ (the dataset) where each element $x_i$ (an instance) is a 2d vector, $M$ will apply the same matrix multiplication to each element $x_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "811b1520-a06f-49a6-9f5a-a020f6a659e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5497,  5.1057, -2.1184,  0.4064, -0.6317,  0.4988, -0.6548,  0.1119],\n",
       "        [-1.3547,  4.4571, -1.5512,  0.2202, -0.6899,  0.3760, -0.4629,  0.1730],\n",
       "        [-0.7650,  2.4702,  1.3598, -0.8800, -1.4131, -0.2342,  0.5528,  0.6569],\n",
       "        [-2.5047,  8.1831, -0.1162, -0.8291, -2.5353,  0.1456,  0.1463,  1.0081]],\n",
       "       grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ec4527-ee17-4d07-ac79-0ebf9aef20ff",
   "metadata": {},
   "source": [
    "We can chain this with a second matrix $M2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b855a837-0384-4bc4-8f69-a09e69e99b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=8, out_features=1, bias=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M2 = nn.Linear(8,1, bias=False)\n",
    "M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7d6994a-9faa-45af-b3fc-31a4841d3d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0330, 0.0999, 0.5847, 0.8350], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M2(M1(x)).squeeze() #to automatically remove the extra dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83643b9a-eb6a-415d-9534-99710331bbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 5., 2., 5.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4076aa90-6a07-441a-bef7-57301e3bb10c",
   "metadata": {},
   "source": [
    "The weights of the matrices `M1` and `M2` consitute the weights $a$ of the network defined above. In order to optimize for these weights, we first construct our network $f$ as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8fd49a0-f43f-49c6-9096-f9b9ce286997",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNeuralNet(nn.Module):  \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.Matrix1 = nn.Linear(2,8,bias=False)\n",
    "        self.Matrix2 = nn.Linear(8,1,bias=False)\n",
    "    def forward(self,x): #use the NN onto some data x\n",
    "        x = self.Matrix1(x)\n",
    "        x = self.Matrix2(x)\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f7a476-28b7-4da8-bce8-47d317b0c686",
   "metadata": {},
   "source": [
    "Constructing the network using a subclass of the `nn.Module` allows the parameters of the network to be conveniently stored. This will be useful later when we need to adjust them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7676ea25-0339-4fa7-9829-4db46f459c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = MyNeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a6a0b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1800, -0.2758],\n",
      "        [ 0.3951,  0.3343],\n",
      "        [-0.1031, -0.0393],\n",
      "        [ 0.6553,  0.6036],\n",
      "        [ 0.4450,  0.5514],\n",
      "        [-0.3369, -0.0033],\n",
      "        [-0.1900, -0.5217],\n",
      "        [-0.3062, -0.5385]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1484, -0.0768,  0.1165, -0.1241, -0.3297, -0.2045,  0.1341,  0.2604]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for par in f.parameters():\n",
    "    print(par)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd606ed3-1e16-40a0-9d83-75f57007cc20",
   "metadata": {},
   "source": [
    "Pass in data to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2137968-63d5-4549-8517-4eb29886ea7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.0754, -2.7420, -1.9457, -5.5586], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = f(x)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "941d1f28-f9ea-4039-9d9b-83e6b8901ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 5., 2., 5.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cd1980-df69-47ca-9973-e84b8ff70a84",
   "metadata": {},
   "source": [
    "# Adjusting $a$ so that $\\hat{y}$ and $y$ are similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5224ea-6ca1-47ac-884d-125a4c7a8f80",
   "metadata": {},
   "source": [
    "Now we define the loss function $L$, which provides a metric of similarity between $y$ and $\\hat{y}$. In this case, we will use the mean squared error loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36e7a8cb-56de-4f7d-a81b-e8b85ac669f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(50.9000, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = nn.MSELoss()\n",
    "L(y,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271f31de-746a-423d-9250-b37b057f814e",
   "metadata": {},
   "source": [
    "Confirming it is doing the same as the regular mean-squared error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96b81fc5-cd7f-4a4e-ba46-d23b699b0480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(50.9000, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean((y-yhat)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1fcb92-6d0b-4fa4-8bf2-25ec007e284c",
   "metadata": {},
   "source": [
    "Note that $L$ depends on $a$, since our predictions $\\hat{y}$ depend on the parameters of the network $a$. In this sense, $L=L(a)$. **The main idea behind machine learning** is to compute\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial a_i}$$\n",
    "\n",
    "for each parameter $a_i$ of the network. Then we adjust each parameter as follows:\n",
    "\n",
    "$$a_i \\to a_i - \\ell \\frac{\\partial L}{\\partial a_i}$$\n",
    "\n",
    "where $\\ell$ is the learning rate.\n",
    "\n",
    "**Example**: A loss function that only depends on one parameter:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0597b16f-0c73-4da0-9bd7-a0c64fc0a0f4",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"../images/loss.PNG\" alt=\"drawing\" width=\"500\" align=\"center\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64040428-c794-44ad-aa72-504df520e4cc",
   "metadata": {},
   "source": [
    "The idea is to do this over and over again, until one reaches a minimum for $L$. This is called **gradient descent**.\n",
    "\n",
    "* Each pass of the full data set $x$ is called an **epoch**. In this case, we are evaluating $\\partial L/\\partial a_i$ on the entire dataset $x$ each time we iterate $a_i \\to a_i - \\ell \\frac{\\partial L}{\\partial a_i}$, so each iteration corresponds to an epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15529920-1629-42cc-9d80-2ce21b5904aa",
   "metadata": {},
   "source": [
    "The `SGD`(meaning stochastic gradient descent) takes in all model parameters $a$ along with the learning rate $\\ell$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "270691bf-40c7-4d74-934f-4dd558957af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(f.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb3e740-fd5d-445e-9df4-11e8c54a424b",
   "metadata": {},
   "source": [
    "Adjust the parameters over and over:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d07cfd9c-2bcc-4d71-bf47-6b6609107db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "for _ in range(50):\n",
    "    opt.zero_grad() # flush previous epoch's gradient\n",
    "    loss_value = L(f(x), y) #compute loss\n",
    "    loss_value.backward() # compute gradient\n",
    "    opt.step() # Perform iteration using gradient above\n",
    "    losses.append(loss_value.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed26a8ac-bb89-4f92-9e83-3309e83b58b2",
   "metadata": {},
   "source": [
    "Plot $L(a)$ as a function of number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c485d7a-2593-40b0-8563-998648cb2b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epochs')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.ylabel('Loss $L(y,\\hat{y};a)$')\n",
    "plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cbcbdf-3a6f-43be-9e04-f985ddd667cc",
   "metadata": {},
   "source": [
    "This is as close as we can make the model $f$ predict $y$ from $x$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9e558fa-728f-4ea0-a754-ef462c8d83a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.2438, 2.8123, 1.4131, 4.9841], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8568c65f-5566-4aaf-9412-1a09e6bf8b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 5., 2., 5.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec199b6-e8a5-41b0-b79e-5b57e4cf2588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4ab89ba51e9d8b7a5eba3759751cafe3b233e8e716d096834d66cd3a9964ede4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
